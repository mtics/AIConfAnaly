"""
ä½¿ç”¨ç¤ºä¾‹ - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Paperç±»å’ŒMilvusæ•°æ®åº“ç³»ç»Ÿ
"""

import sys
from pathlib import Path
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from models.paper import Paper, TaskScenarioAnalysis, PaperMetrics
from services.paper_service import PaperService
from database.milvus_client import MilvusClientConfig
from batch_processor import BatchProcessor, QueryInterface

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def example_single_paper():
    """ç¤ºä¾‹1: å¤„ç†å•ç¯‡è®ºæ–‡"""
    print("=" * 50)
    print("ç¤ºä¾‹1: å¤„ç†å•ç¯‡è®ºæ–‡")
    print("=" * 50)
    
    # åˆå§‹åŒ–æœåŠ¡
    paper_service = PaperService(
        encoder_type='sentence-transformer',
        enable_cache=True
    )
    
    # å¤„ç†è®ºæ–‡
    paper = paper_service.process_and_store_paper(
        title="Deep Learning for Automated Skin Cancer Detection in Dermatoscopy Images",
        abstract="This paper presents a novel approach for automated detection of skin cancer using deep convolutional neural networks. We analyze dermatoscopy images to classify skin lesions as benign or malignant, achieving 94% accuracy on a dataset of 10,000 images. Our method could help dermatologists in early cancer detection and improve patient outcomes.",
        conference="MICCAI",
        year=2023,
        url="https://example.com/paper1"
    )
    
    if paper:
        print(f"âœ“ è®ºæ–‡å¤„ç†æˆåŠŸ: {paper.paper_id}")
        print(f"  æ ‡é¢˜: {paper.title}")
        print(f"  åº”ç”¨åœºæ™¯: {paper.task_scenario_analysis.application_scenario}")
        print(f"  ä»»åŠ¡ç±»å‹: {paper.task_scenario_analysis.task_type}")
        print(f"  ç½®ä¿¡åº¦: {paper.task_scenario_analysis.scenario_confidence:.3f}")
        print(f"  å‘é‡ç»´åº¦: {paper.text_embedding.shape if paper.text_embedding is not None else 'None'}")
    else:
        print("âœ— è®ºæ–‡å¤„ç†å¤±è´¥")


def example_batch_processing():
    """ç¤ºä¾‹2: æ‰¹é‡å¤„ç†è®ºæ–‡"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹2: æ‰¹é‡å¤„ç†è®ºæ–‡")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
    processor = BatchProcessor(
        milvus_host="localhost",
        milvus_port="19530",
        encoder_type="sentence-transformer"
    )
    
    # ç¤ºä¾‹è®ºæ–‡æ•°æ®
    sample_papers = [
        {
            'title': 'Reinforcement Learning for Autonomous Vehicle Path Planning in Urban Environments',
            'abstract': 'We propose a reinforcement learning approach for path planning in autonomous vehicles. Our method learns optimal driving policies in complex urban scenarios with dynamic obstacles and traffic rules.',
            'conference': 'ICRA',
            'year': 2023,
            'url': 'https://example.com/paper2'
        },
        {
            'title': 'Machine Learning Analysis of Financial Market Trends for Risk Assessment',
            'abstract': 'This study presents an empirical analysis of machine learning methods for predicting stock market movements. We evaluate various algorithms for financial risk assessment and portfolio optimization.',
            'conference': 'AAAI',
            'year': 2023,
            'url': 'https://example.com/paper3'
        },
        {
            'title': 'Natural Language Processing for Clinical Decision Support Systems',
            'abstract': 'We develop an NLP system to assist healthcare professionals in clinical decision making. Our approach extracts relevant information from electronic health records to support diagnostic processes.',
            'conference': 'ACL',
            'year': 2023,
            'url': 'https://example.com/paper4'
        }
    ]
    
    # æ‰¹é‡å¤„ç†
    processed_papers, stats = processor.paper_service.batch_process_papers(
        papers_data=sample_papers,
        batch_size=10,
        analyze_all=True,
        store_all=True
    )
    
    print(f"âœ“ æ‰¹é‡å¤„ç†å®Œæˆ")
    print(f"  æ€»è®¡: {stats['total_papers']} ç¯‡è®ºæ–‡")
    print(f"  æˆåŠŸå¤„ç†: {stats['processed_papers']} ç¯‡")
    print(f"  æˆåŠŸå­˜å‚¨: {stats['inserted_papers']} ç¯‡")
    print(f"  å¤„ç†æ—¶é—´: {stats['processing_time']:.2f} ç§’")
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    for paper in processed_papers:
        if paper.task_scenario_analysis:
            print(f"\n  ğŸ“„ {paper.title[:50]}...")
            print(f"     åº”ç”¨åœºæ™¯: {paper.task_scenario_analysis.application_scenario}")
            print(f"     ä»»åŠ¡ç±»å‹: {paper.task_scenario_analysis.task_type}")


def example_search_and_query():
    """ç¤ºä¾‹3: æœç´¢å’ŒæŸ¥è¯¢è®ºæ–‡"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹3: æœç´¢å’ŒæŸ¥è¯¢è®ºæ–‡")
    print("=" * 50)
    
    # åˆå§‹åŒ–æŸ¥è¯¢æ¥å£
    query_interface = QueryInterface(
        milvus_host="localhost",
        milvus_port="19530"
    )
    
    # 1. æ–‡æœ¬æœç´¢
    print("\n1. æ–‡æœ¬æœç´¢ - 'åŒ»ç–—è¯Šæ–­':")
    results = query_interface.search_papers(
        query="åŒ»ç–—è¯Šæ–­ çš®è‚¤ç™Œæ£€æµ‹",
        search_type="text",
        top_k=3
    )
    
    for i, paper in enumerate(results, 1):
        print(f"   {i}. {paper.get('title', 'No title')[:60]}...")
        print(f"      ç›¸ä¼¼åº¦: {paper.get('score', 0):.3f}")
        print(f"      ä¼šè®®: {paper.get('conference', 'Unknown')} ({paper.get('year', 'Unknown')})")
    
    # 2. æ··åˆæœç´¢
    print("\n2. æ··åˆæœç´¢ - 'è‡ªåŠ¨é©¾é©¶è·¯å¾„è§„åˆ’':")
    results = query_interface.search_papers(
        query="è‡ªåŠ¨é©¾é©¶ è·¯å¾„è§„åˆ’ å¼ºåŒ–å­¦ä¹ ",
        search_type="hybrid",
        top_k=3
    )
    
    for i, paper in enumerate(results, 1):
        print(f"   {i}. {paper.get('title', 'No title')[:60]}...")
        print(f"      ç»¼åˆå¾—åˆ†: {paper.get('combined_score', paper.get('score', 0)):.3f}")
        print(f"      åº”ç”¨åœºæ™¯: {paper.get('application_scenario', 'Unknown')}")
    
    # 3. è¿‡æ»¤æŸ¥è¯¢
    print("\n3. è¿‡æ»¤æŸ¥è¯¢ - 2023å¹´AAAIä¼šè®®:")
    results = query_interface.get_papers_by_filters(
        filters={
            'conference': 'AAAI',
            'year': 2023
        },
        limit=5
    )
    
    for i, paper in enumerate(results, 1):
        print(f"   {i}. {paper.get('title', 'No title')[:60]}...")
        print(f"      ä»»åŠ¡ç±»å‹: {paper.get('task_type', 'Unknown')}")


def example_database_statistics():
    """ç¤ºä¾‹4: æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹4: æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 50)
    
    # åˆå§‹åŒ–æŸ¥è¯¢æ¥å£
    query_interface = QueryInterface()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = query_interface.get_statistics()
    
    print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
    print(f"  å·²å¤„ç†è®ºæ–‡: {stats.get('processed_papers', 0)}")
    print(f"  å·²å­˜å‚¨è®ºæ–‡: {stats.get('inserted_papers', 0)}")
    print(f"  å¤±è´¥è®ºæ–‡: {stats.get('failed_papers', 0)}")
    
    if 'encoder_info' in stats:
        encoder_info = stats['encoder_info']
        print(f"\nğŸ”§ ç¼–ç å™¨ä¿¡æ¯:")
        print(f"  ç±»å‹: {encoder_info.get('type', 'Unknown')}")
        print(f"  å‘é‡ç»´åº¦: {encoder_info.get('dimension', 'Unknown')}")
        
        if 'cache_stats' in encoder_info:
            cache_stats = encoder_info['cache_stats']
            print(f"  ç¼“å­˜æ–‡ä»¶: {cache_stats.get('total_files', 0)}")
            print(f"  ç¼“å­˜å¤§å°: {cache_stats.get('total_size_mb', 0):.2f} MB")


def example_export_data():
    """ç¤ºä¾‹5: å¯¼å‡ºæ•°æ®"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹5: å¯¼å‡ºæ•°æ®")
    print("=" * 50)
    
    # åˆå§‹åŒ–æŸ¥è¯¢æ¥å£
    query_interface = QueryInterface()
    
    # å¯¼å‡ºæœç´¢ç»“æœ
    success = query_interface.export_search_results(
        query="æœºå™¨å­¦ä¹  æ·±åº¦å­¦ä¹ ",
        output_path="outputs/search_results.json",
        search_type="hybrid",
        top_k=20,
        format="json"
    )
    
    if success:
        print("âœ“ æœç´¢ç»“æœå·²å¯¼å‡ºåˆ° outputs/search_results.json")
    else:
        print("âœ— å¯¼å‡ºå¤±è´¥")
    
    # ä½¿ç”¨PaperServiceå¯¼å‡ºè¿‡æ»¤æ•°æ®
    paper_service = PaperService()
    success = paper_service.export_papers(
        output_path="outputs/all_papers.csv",
        filters={'year_range': [2020, 2023]},
        format="csv"
    )
    
    if success:
        print("âœ“ è®ºæ–‡æ•°æ®å·²å¯¼å‡ºåˆ° outputs/all_papers.csv")
    else:
        print("âœ— å¯¼å‡ºå¤±è´¥")


def example_paper_similarity():
    """ç¤ºä¾‹6: è®ºæ–‡ç›¸ä¼¼æ€§åˆ†æ"""
    print("\n" + "=" * 50)
    print("ç¤ºä¾‹6: è®ºæ–‡ç›¸ä¼¼æ€§åˆ†æ")
    print("=" * 50)
    
    # åˆå§‹åŒ–æŸ¥è¯¢æ¥å£
    query_interface = QueryInterface()
    
    # é¦–å…ˆæœç´¢ä¸€ç¯‡è®ºæ–‡
    search_results = query_interface.search_papers(
        query="æ·±åº¦å­¦ä¹ ",
        top_k=1
    )
    
    if search_results:
        target_paper = search_results[0]
        paper_id = target_paper.get('paper_id')
        
        print(f"ç›®æ ‡è®ºæ–‡: {target_paper.get('title', 'No title')[:60]}...")
        
        # æŸ¥æ‰¾ç›¸ä¼¼è®ºæ–‡
        similar_papers = query_interface.get_similar_papers(
            paper_id=paper_id,
            top_k=5
        )
        
        print(f"\næ‰¾åˆ° {len(similar_papers)} ç¯‡ç›¸ä¼¼è®ºæ–‡:")
        for i, paper in enumerate(similar_papers, 1):
            print(f"  {i}. {paper.get('title', 'No title')[:60]}...")
            print(f"     ç›¸ä¼¼åº¦: {paper.get('score', 0):.3f}")
            print(f"     åº”ç”¨åœºæ™¯: {paper.get('application_scenario', 'Unknown')}")
    else:
        print("æœªæ‰¾åˆ°è®ºæ–‡è¿›è¡Œç›¸ä¼¼æ€§åˆ†æ")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ Paperç±»å’ŒMilvusæ•°æ®åº“ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹")
    print("æ³¨æ„: ç¡®ä¿MilvusæœåŠ¡å™¨åœ¨localhost:19530è¿è¡Œ")
    
    try:
        # è¿è¡Œç¤ºä¾‹
        example_single_paper()
        example_batch_processing()
        example_search_and_query()
        example_database_statistics()
        example_export_data()
        example_paper_similarity()
        
        print("\n" + "=" * 50)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("=" * 50)
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥:")
        print("1. MilvusæœåŠ¡å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. ä¾èµ–åŒ…æ˜¯å¦å·²å®‰è£…")


if __name__ == "__main__":
    main()